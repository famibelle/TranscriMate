# TranscriMate ğŸ™ï¸

TranscriMate est une application de transcription audio/vidÃ©o intelligente qui utilise l'IA pour sÃ©parer les voix, transcrire le contenu et permettre d'interagir avec les transcriptions via un chatbot.

## ğŸš€ FonctionnalitÃ©s

- **Transcription audio/vidÃ©o** : Conversion automatique de fichiers audio et vidÃ©o en texte
- **SÃ©paration des locuteurs** : Identification et sÃ©paration automatique des diffÃ©rentes voix
- **Traduction** : Traduction automatique vers l'anglais
- **Chatbot IA** : Interaction avec les transcriptions via AKABot (GPT-4 ou Chocolatine)
- **Transcription en temps rÃ©el** : Enregistrement et transcription live via microphone
- **Interface moderne** : Interface web responsive avec mode sombre/clair

## ğŸ“‹ PrÃ©requis

### Backend
- Python 3.10+
- CUDA (recommandÃ© pour les performances GPU)
- ffmpeg installÃ© sur le systÃ¨me

### Frontend  
- Node.js 18.3.0+
- npm

### ClÃ©s API requises
- `OPENAI_API_KEY` : Pour GPT-4 et Whisper
- `HuggingFace_API_KEY` : Pour les modÃ¨les Hugging Face

## ğŸ› ï¸ Installation et Configuration

### 1. Cloner le projet
```bash
git clone https://github.com/famibelle/TranscriMate.git
cd TranscriMate
```

### 2. Configuration des variables d'environnement

CrÃ©ez un fichier `.env` dans le dossier `backend/` :

```bash
# Backend/.env
OPENAI_API_KEY_MCF=votre_clÃ©_openai
HuggingFace_API_KEY=votre_clÃ©_huggingface
SERVER_URL=http://localhost:8000
```

CrÃ©ez un fichier `.env` dans le dossier `frontend/` :

```bash
# Frontend/.env
VUE_APP_API_URL=http://localhost:8000
VUE_APP_WEBSOCKET_URL=ws://localhost:8000/streaming_audio/
```

## ğŸš€ DÃ©marrage avec Docker (RecommandÃ©)

### Option 1: Docker Compose (Le plus simple)

```bash
# Construire et lancer tous les services
docker-compose up --build

# En arriÃ¨re-plan
docker-compose up -d --build

# ArrÃªter les services
docker-compose down
```

L'application sera accessible sur :
- Frontend : http://localhost:8080
- Backend API : http://localhost:8000

### Option 2: Docker individuel

#### Backend
```bash
cd backend
docker build -t transcrimate-backend .
docker run -p 8000:8000 --gpus all transcrimate-backend
```

#### Frontend
```bash
cd frontend
docker build -t transcrimate-frontend .
docker run -p 8080:8080 transcrimate-frontend
```

## ğŸ’» DÃ©marrage en ligne de commande (DÃ©veloppement)

### Backend

```bash
cd backend

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt

# Lancer le serveur
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

Le backend sera accessible sur http://localhost:8000

### Frontend

```bash
cd frontend

# Installer les dÃ©pendances
npm install

# Lancer en mode dÃ©veloppement
npm run serve

# Construire pour la production
npm run build
```

Le frontend sera accessible sur http://localhost:8080

## ğŸ“± Utilisation

### 1. Transcription de fichiers

1. AccÃ©dez Ã  l'onglet **Transcription ğŸ™ï¸**
2. Glissez-dÃ©posez un fichier audio/vidÃ©o ou utilisez le bouton "SÃ©lectionner un fichier"
3. Configurez les paramÃ¨tres :
   - **Transcrire** : Transcription dans la langue originale
   - **Traduire** : Traduction vers l'anglais
4. Attendez le traitement automatique (extraction audio â†’ sÃ©paration des voix â†’ transcription)
5. Consultez les rÃ©sultats par locuteur et copiez la transcription complÃ¨te

### 2. Chatbot AKABot

1. AccÃ©dez Ã  l'onglet **AKABot ğŸ¤–**
2. Choisissez le modÃ¨le :
   - **OpenAI GPT** : GPT-4 pour des rÃ©ponses de haute qualitÃ©
   - **Chocolatine ğŸ«ğŸ¥–** : ModÃ¨le franÃ§ais local
3. Posez vos questions sur AKABI ou analysez une transcription

### 3. Transcription en temps rÃ©el

1. AccÃ©dez Ã  l'onglet **Traduction ğŸ—£ï¸**
2. Configurez le mode (transcription/traduction)
3. Cliquez sur le bouton microphone pour dÃ©marrer l'enregistrement
4. Parlez et visualisez la transcription en temps rÃ©el

## ğŸ”§ Configuration avancÃ©e

### ModÃ¨les Whisper disponibles
- `openai/whisper-large-v3-turbo` (recommandÃ©)
- `openai/whisper-large-v3`
- `openai/whisper-medium`
- `openai/whisper-small`
- `openai/whisper-base`
- `openai/whisper-tiny`

### ParamÃ¨tres systÃ¨me

Le backend utilise automatiquement :
- GPU CUDA si disponible (recommandÃ©)
- CPU sinon (plus lent)
- Gestion automatique de la mÃ©moire avec dÃ©chargement des modÃ¨les aprÃ¨s inactivitÃ©

## ğŸ“ Structure du projet

```
TranscriMate/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # API FastAPI principale  
â”‚   â”œâ”€â”€ RAG.py               # SystÃ¨me de recherche pour AKABot
â”‚   â”œâ”€â”€ requirements.txt     # DÃ©pendances Python
â”‚   â”œâ”€â”€ Dockerfile          # Configuration Docker backend
â”‚   â””â”€â”€ Multimedia/
â”‚       â””â”€â”€ Use_Cases/      # Base de connaissances AKABI
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.vue         # Composant principal
â”‚   â”‚   â”œâ”€â”€ main.js         # Point d'entrÃ©e
â”‚   â”‚   â””â”€â”€ components/     # Composants Vue.js
â”‚   â”œâ”€â”€ package.json        # DÃ©pendances Node.js
â”‚   â””â”€â”€ Dockerfile         # Configuration Docker frontend
â”œâ”€â”€ docker-compose.yaml    # Orchestration Docker
â””â”€â”€ README.md             # Ce fichier
```

## ğŸ› ï¸ Scripts utiles

### Backend
```bash
# VÃ©rifier l'Ã©tat des modÃ¨les
curl http://localhost:8000/device_type/

# Initialiser les modÃ¨les
curl http://localhost:8000/initialize/

# Maintenir les modÃ¨les en vie
curl http://localhost:8000/keep_alive/
```

### DÃ©veloppement
```bash
# Lancer les tests backend
cd backend && python -m pytest

# Linter frontend  
cd frontend && npm run lint

# Construire pour la production
cd frontend && npm run build
```

## ğŸ› DÃ©pannage

### ProblÃ¨mes courants

1. **Erreur CUDA** : VÃ©rifiez que CUDA est installÃ© et compatible
2. **ModÃ¨les trop lents** : Utilisez un modÃ¨le Whisper plus petit (tiny/base/small)
3. **Erreur de mÃ©moire** : RÃ©duisez la taille des fichiers ou utilisez CPU
4. **ProblÃ¨me de CORS** : VÃ©rifiez les URLs dans les fichiers .env

### Logs
```bash
# Logs Docker Compose
docker-compose logs -f

# Logs d'un service spÃ©cifique  
docker-compose logs -f backend
docker-compose logs -f frontend
```

## ğŸ“Š Formats supportÃ©s

### Audio
- MP3, WAV, AAC, OGG, FLAC, M4A

### VidÃ©o  
- MP4, MOV, 3GP, MKV

## âš¡ Performances

### Recommandations systÃ¨me
- **CPU** : 8+ cÅ“urs recommandÃ©s
- **RAM** : 16GB minimum, 32GB recommandÃ©
- **GPU** : NVIDIA avec CUDA pour l'accÃ©lÃ©ration
- **Stockage** : SSD recommandÃ© pour les gros fichiers

### Optimisations
- Utilisez Docker avec `--gpus all` pour l'accÃ©lÃ©ration GPU
- Les modÃ¨les se dÃ©chargent automatiquement aprÃ¨s 10 minutes d'inactivitÃ©
- La transcription temps rÃ©el optimise automatiquement la qualitÃ© vs latence

## ğŸ¤ Contribution

1. Forkez le projet
2. CrÃ©ez une branche feature (`git checkout -b feature/AmazingFeature`)
3. Committez vos changes (`git commit -m 'Add some AmazingFeature'`)
4. Pushez vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrez une Pull Request

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ™ Remerciements

- OpenAI pour Whisper et GPT-4
- Pyannote pour la diarisation des locuteurs  
- Hugging Face pour les modÃ¨les de transformers
- L'Ã©quipe AKABI pour les cas d'usage

---

**DÃ©veloppÃ© avec â¤ï¸ par l'Ã©quipe AKABI**